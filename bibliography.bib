@ARTICLE{Meehl1967-ij,
  title     = "{Theory-Testing} in Psychology and Physics: A Methodological
               Paradox",
  author    = "Meehl, Paul E",
  abstract  = "Because physical theories typically predict numerical values, an
               improvement in experimental precision reduces the tolerance
               range and hence increases corroborability. In most psychological
               research, improved power of a statistical design leads to a
               prior probability approaching 1/2 of finding a significant
               difference in the theoretically predicted direction. Hence the
               corroboration yielded by ``success'' is very weak, and becomes
               weaker with increased precision. ``Statistical significance''
               plays a logical role in psychology precisely the reverse of its
               role in physics. This problem is worsened by certain unhealthy
               tendencies prevalent among psychologists, such as a premium
               placed on experimental ``cuteness'' and a free reliance upon ad
               hoc explanations to avoid refutation.",
  journal   = "Philos. Sci.",
  publisher = "The University of Chicago Press",
  volume    =  34,
  number    =  2,
  pages     = "103--115",
  month     =  jun,
  year      =  1967
}

@ARTICLE{Rozeboom1960-dp,
  title   = "The fallacy of the null-hypothesis significance test",
  author  = "Rozeboom, William W",
  journal = "Psychol. Bull.",
  volume  =  57,
  number  =  5,
  pages   = "416--428",
  year    =  1960
}

@ARTICLE{Skudlarski1999-ao,
  title    = "{ROC} analysis of statistical methods used in functional {MRI}:
              individual subjects",
  author   = "Skudlarski, P and Constable, R T and Gore, J C",
  abstract = "The complicated structure of fMRI signals and associated noise
              sources make it difficult to assess the validity of various steps
              involved in the statistical analysis of brain activation. Most
              methods used for fMRI analysis assume that observations are
              independent and that the noise can be treated as white gaussian
              noise. These assumptions are usually not true but it is difficult
              to assess how severely these assumptions are violated and what
              are their practical consequences. In this study a direct
              comparison is made between the power of various analytical
              methods used to detect activations, without reference to
              estimates of statistical significance. The statistics used in
              fMRI are treated as metrics designed to detect activations and
              are not interpreted probabilistically. The receiver operator
              characteristic (ROC) method is used to compare the efficacy of
              various steps in calculating an activation map in the study of a
              single subject based on optimizing the ratio of the number of
              detected activations to the number of false-positive findings.
              The main findings are as follows: Preprocessing. The removal of
              intensity drifts and high-pass filtering applied on the voxel
              time-course level is beneficial to the efficacy of analysis.
              Temporal normalization of the global image intensity, smoothing
              in the temporal domain, and low-pass filtering do not improve
              power of analysis. Choices of statistics. the cross-correlation
              coefficient and t-statistic, as well as nonparametric
              Mann-Whitney statistics, prove to be the most effective and are
              similar in performance, by our criterion. Task design. the proper
              design of task protocols is shown to be crucial. In an
              alternating block design the optimal block length is be
              approximately 18 s. Spatial clustering. an initial spatial
              smoothing of images is more efficient than cluster filtering of
              the statistical parametric activation maps.",
  journal  = "Neuroimage",
  volume   =  9,
  number   =  3,
  pages    = "311--329",
  month    =  mar,
  year     =  1999,
  language = "en"
}

@ARTICLE{Lund2005-sf,
  title    = "Motion or activity: their role in intra- and inter-subject
              variation in {fMRI}",
  author   = "Lund, Torben E and N{\o}rgaard, Minna D and Rostrup, Egill and
              Rowe, James B and Paulson, Olaf B",
  abstract = "Functional MRI (fMRI) carries the potential for non-invasive
              measurements of brain activity. Typically, what are referred to
              as activation images are actually thresholded statistical
              parametric maps. These maps possess large inter-session
              variability. This is especially problematic when applying fMRI to
              pre-surgical planning because of a higher requirement for
              intra-subject precision. The purpose of this study was to
              investigate the impact of residual movement artefacts on
              intra-subject and inter-subject variability in the observed fMRI
              activation. Ten subjects were examined using three different
              word-generation tasks. Two of the subjects were examined 10 times
              on 10 different days using the same paradigms. We systematically
              investigated one approach of correcting for residual movement
              effects: the inclusion of regressors describing movement-related
              effects in the design matrix of a General Linear Model (GLM). The
              data were analysed with and without modeling the residual
              movement artefacts and the impact on inter-session variance was
              assessed using F-contrasts. Inclusion of motion parameters in the
              analysis significantly reduced both the intra-subject as well as
              the inter-subject-variance.",
  journal  = "Neuroimage",
  volume   =  26,
  number   =  3,
  pages    = "960--964",
  month    =  jul,
  year     =  2005,
  language = "en"
}

@ARTICLE{Woo2014-ji,
  title    = "Cluster-extent based thresholding in {fMRI} analyses: pitfalls
              and recommendations",
  author   = "Woo, Choong-Wan and Krishnan, Anjali and Wager, Tor D",
  abstract = "Cluster-extent based thresholding is currently the most popular
              method for multiple comparisons correction of statistical maps in
              neuroimaging studies, due to its high sensitivity to weak and
              diffuse signals. However, cluster-extent based thresholding
              provides low spatial specificity; researchers can only infer that
              there is signal somewhere within a significant cluster and cannot
              make inferences about the statistical significance of specific
              locations within the cluster. This poses a particular problem
              when one uses a liberal cluster-defining primary threshold (i.e.,
              higher p-values), which often produces large clusters spanning
              multiple anatomical regions. In such cases, it is impossible to
              reliably infer which anatomical regions show true effects. From a
              survey of 814 functional magnetic resonance imaging (fMRI)
              studies published in 2010 and 2011, we show that the use of
              liberal primary thresholds (e.g., p<.01) is endemic, and that the
              largest determinant of the primary threshold level is the default
              option in the software used. We illustrate the problems with
              liberal primary thresholds using an fMRI dataset from our
              laboratory (N=33), and present simulations demonstrating the
              detrimental effects of liberal primary thresholds on false
              positives, localization, and interpretation of fMRI findings. To
              avoid these pitfalls, we recommend several analysis and reporting
              procedures, including 1) setting primary p<.001 as a default
              lower limit; 2) using more stringent primary thresholds or
              voxel-wise correction methods for highly powered studies; and 3)
              adopting reporting practices that make the level of spatial
              precision transparent to readers. We also suggest alternative and
              supplementary analysis methods.",
  journal  = "Neuroimage",
  volume   =  91,
  pages    = "412--419",
  month    =  may,
  year     =  2014,
  keywords = "Cluster-extent thresholding; FSL; False discovery rate;
              Family-wise error rate; Gaussian random fields; Multiple
              comparisons; Primary threshold; SPM; fMRI",
  language = "en"
}

@ARTICLE{Carp2013-cm,
  title    = "Optimizing the order of operations for movement scrubbing:
              Comment on Power et al",
  author   = "Carp, Joshua",
  abstract = "A recent study by Power and colleagues shows that BOLD artifacts
              induced by head movement can substantially alter patterns of
              resting-state functional connectivity and proposes a novel
              procedure for reducing these artifacts by deleting (or
              ``scrubbing'') movement-contaminated volumes. The authors
              acknowledge that this work is descriptive and not prescriptive,
              and note that future studies may refine the proposed scrubbing
              method. Nevertheless, it is worth pointing out that this method
              can be improved substantially by a single transposition in the
              order of operations. Temporal filtering is known to introduce
              ringing artifacts that emanate from sharp transitions in signal
              intensity. The method proposed in the target article applies
              temporal filtering before deleting contaminated volumes-in
              effect, spreading movement-related artifacts backwards and
              forwards in time, but deleting only the originally contaminated
              data. Using simulated data, we show that deleting and replacing
              contaminated volumes before temporal filtering removes a greater
              proportion of artifactual signal while retaining a greater
              proportion of the original data.",
  journal  = "Neuroimage",
  volume   =  76,
  pages    = "436--438",
  month    =  aug,
  year     =  2013,
  language = "en"
}

@ARTICLE{Woolrich2001-tk,
  title    = "Temporal autocorrelation in univariate linear modeling of {FMRI}
              data",
  author   = "Woolrich, M W and Ripley, B D and Brady, M and Smith, S M",
  abstract = "In functional magnetic resonance imaging statistical analysis
              there are problems with accounting for temporal autocorrelations
              when assessing change within voxels. Techniques to date have
              utilized temporal filtering strategies to either shape these
              autocorrelations or remove them. Shaping, or ``coloring,''
              attempts to negate the effects of not accurately knowing the
              intrinsic autocorrelations by imposing known autocorrelation via
              temporal filtering. Removing the autocorrelation, or
              ``prewhitening,'' gives the best linear unbiased estimator,
              assuming that the autocorrelation is accurately known. For
              single-event designs, the efficiency of the estimator is
              considerably higher for prewhitening compared with coloring.
              However, it has been suggested that sufficiently accurate
              estimates of the autocorrelation are currently not available to
              give prewhitening acceptable bias. To overcome this, we consider
              different ways to estimate the autocorrelation for use in
              prewhitening. After high-pass filtering is performed, a Tukey
              taper (set to smooth the spectral density more than would
              normally be used in spectral density estimation) performs best.
              Importantly, estimation is further improved by using nonlinear
              spatial filtering to smooth the estimated autocorrelation, but
              only within tissue type. Using this approach when prewhitening
              reduced bias to close to zero at probability levels as low as 1 x
              10(-5).",
  journal  = "Neuroimage",
  volume   =  14,
  number   =  6,
  pages    = "1370--1386",
  month    =  dec,
  year     =  2001,
  language = "en"
}

@ARTICLE{Ioannidis2005-sy,
  title    = "Why most published research findings are false",
  author   = "Ioannidis, John P A",
  abstract = "There is increasing concern that most current published research
              findings are false. The probability that a research claim is true
              may depend on study power and bias, the number of other studies
              on the same question, and, importantly, the ratio of true to no
              relationships among the relationships probed in each scientific
              field. In this framework, a research finding is less likely to be
              true when the studies conducted in a field are smaller; when
              effect sizes are smaller; when there is a greater number and
              lesser preselection of tested relationships; where there is
              greater flexibility in designs, definitions, outcomes, and
              analytical modes; when there is greater financial and other
              interest and prejudice; and when more teams are involved in a
              scientific field in chase of statistical significance.
              Simulations show that for most study designs and settings, it is
              more likely for a research claim to be false than true. Moreover,
              for many current scientific fields, claimed research findings may
              often be simply accurate measures of the prevailing bias. In this
              essay, I discuss the implications of these problems for the
              conduct and interpretation of research.",
  journal  = "PLoS Med.",
  volume   =  2,
  number   =  8,
  pages    = "e124",
  month    =  aug,
  year     =  2005,
  language = "en"
}

@ARTICLE{Carp2012-ph,
  title    = "On the plurality of (methodological) worlds: estimating the
              analytic flexibility of {FMRI} experiments",
  author   = "Carp, Joshua",
  abstract = "How likely are published findings in the functional neuroimaging
              literature to be false? According to a recent mathematical model,
              the potential for false positives increases with the flexibility
              of analysis methods. Functional MRI (fMRI) experiments can be
              analyzed using a large number of commonly used tools, with little
              consensus on how, when, or whether to apply each one. This
              situation may lead to substantial variability in analysis
              outcomes. Thus, the present study sought to estimate the
              flexibility of neuroimaging analysis by submitting a single
              event-related fMRI experiment to a large number of unique
              analysis procedures. Ten analysis steps for which multiple
              strategies appear in the literature were identified, and two to
              four strategies were enumerated for each step. Considering all
              possible combinations of these strategies yielded 6,912 unique
              analysis pipelines. Activation maps from each pipeline were
              corrected for multiple comparisons using five thresholding
              approaches, yielding 34,560 significance maps. While some
              outcomes were relatively consistent across pipelines, others
              showed substantial methods-related variability in activation
              strength, location, and extent. Some analysis decisions
              contributed to this variability more than others, and different
              decisions were associated with distinct patterns of variability
              across the brain. Qualitative outcomes also varied with analysis
              parameters: many contrasts yielded significant activation under
              some pipelines but not others. Altogether, these results reveal
              considerable flexibility in the analysis of fMRI experiments.
              This observation, when combined with mathematical simulations
              linking analytic flexibility with elevated false positive rates,
              suggests that false positive results may be more prevalent than
              expected in the literature. This risk of inflated false positive
              rates may be mitigated by constraining the flexibility of
              analytic choices or by abstaining from selective analysis
              reporting.",
  journal  = "Front. Neurosci.",
  volume   =  6,
  pages    = "149",
  month    =  oct,
  year     =  2012,
  keywords = "analysis flexibility; data analysis; fMRI; false positive
              results; selective reporting",
  language = "en"
}

@ARTICLE{Gonzalez-Castillo2012-do,
  title    = "Whole-brain, time-locked activation with simple tasks revealed
              using massive averaging and model-free analysis",
  author   = "Gonzalez-Castillo, Javier and Saad, Ziad S and Handwerker, Daniel
              A and Inati, Souheil J and Brenowitz, Noah and Bandettini, Peter
              A",
  abstract = "The brain is the body's largest energy consumer, even in the
              absence of demanding tasks. Electrophysiologists report on-going
              neuronal firing during stimulation or task in regions beyond
              those of primary relationship to the perturbation. Although the
              biological origin of consciousness remains elusive, it is argued
              that it emerges from complex, continuous whole-brain neuronal
              collaboration. Despite converging evidence suggesting the whole
              brain is continuously working and adapting to anticipate and
              actuate in response to the environment, over the last 20 y,
              task-based functional MRI (fMRI) have emphasized a
              localizationist view of brain function, with fMRI showing only a
              handful of activated regions in response to task/stimulation.
              Here, we challenge that view with evidence that under optimal
              noise conditions, fMRI activations extend well beyond areas of
              primary relationship to the task; and blood-oxygen
              level-dependent signal changes correlated with task-timing appear
              in over 95\% of the brain for a simple visual stimulation plus
              attention control task. Moreover, we show that response shape
              varies substantially across regions, and that whole-brain
              parcellations based on those differences produce distributed
              clusters that are anatomically and functionally meaningful,
              symmetrical across hemispheres, and reproducible across subjects.
              These findings highlight the exquisite detail lying in fMRI
              signals beyond what is normally examined, and emphasize both the
              pervasiveness of false negatives, and how the sparseness of fMRI
              maps is not a result of localized brain function, but a
              consequence of high noise and overly strict predictive response
              models.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  109,
  number   =  14,
  pages    = "5487--5492",
  month    =  apr,
  year     =  2012,
  language = "en"
}

@ARTICLE{Eklund2016-ak,
  title    = "Cluster failure: Why {fMRI} inferences for spatial extent have
              inflated false-positive rates",
  author   = "Eklund, Anders and Nichols, Thomas E and Knutsson, Hans",
  abstract = "The most widely used task functional magnetic resonance imaging
              (fMRI) analyses use parametric statistical methods that depend on
              a variety of assumptions. In this work, we use real resting-state
              data and a total of 3 million random task group analyses to
              compute empirical familywise error rates for the fMRI software
              packages SPM, FSL, and AFNI, as well as a nonparametric
              permutation method. For a nominal familywise error rate of 5\%,
              the parametric statistical methods are shown to be conservative
              for voxelwise inference and invalid for clusterwise inference.
              Our results suggest that the principal cause of the invalid
              cluster inferences is spatial autocorrelation functions that do
              not follow the assumed Gaussian shape. By comparison, the
              nonparametric permutation test is found to produce nominal
              results for voxelwise as well as clusterwise inference. These
              findings speak to the need of validating the statistical methods
              being used in the field of neuroimaging.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  113,
  number   =  28,
  pages    = "7900--7905",
  month    =  jul,
  year     =  2016,
  keywords = "cluster inference; fMRI; false positives; permutation test;
              statistics",
  language = "en"
}

@ARTICLE{Sommerfeld2018-zl,
  title     = "Confidence Regions for Spatial Excursion Sets From Repeated
               Random Field Observations, With an Application to Climate",
  author    = "Sommerfeld, Max and Sain, Stephan and Schwartzman, Armin",
  abstract  = "ABSTRACTThe goal of this article is to give confidence regions
               for the excursion set of a spatial function above a given
               threshold from repeated noisy observations on a fine grid of
               fixed locations. Given an asymptotically Gaussian estimator of
               the target function, a pair of data-dependent nested excursion
               sets are constructed that are sub- and super-sets of the true
               excursion set, respectively, with a desired confidence.
               Asymptotic coverage probabilities are determined via a
               multiplier bootstrap method, not requiring Gaussianity of the
               original data nor stationarity or smoothness of the limiting
               Gaussian field. The method is used to determine regions in North
               America where the mean summer and winter temperatures are
               expected to increase by mid-21st century by more than 2 degrees
               Celsius.",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  113,
  number    =  523,
  pages     = "1327--1340",
  month     =  jul,
  year      =  2018
}

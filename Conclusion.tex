In this thesis, we have focussed our attention on some of the key issues at the forefront of task-based functional magnetic resonance imaging (fMRI). Our work has been carried out at a pivotal moment in the field's history, during the emergence of population-size neuroimaging studies that are delivering functional data on an unprecedented scale. While fMRI has traditionally been a small data enterprise, where sample sizes of 20 to 30 subjects are common for a task-based study, datasets such as the UK Biobank and Human Connectome Project are now giving researchers the opportunity to analyze fMRI data acquired from tens of thousands of participants. Population neuroimaging projects promise to transform our understanding of brain function, and are already yielding rich results \citep{Miller2016-hd, David_C_Van_Essen2016-bt}. However, the arrival of these datasets has also made this a critical time to reassess the current analysis methods implemented for task-based fMRI, as well as presenting new questions about how to appropriately analyze data of such magnitude.

The challenges posed by the big data revolution have guided all aspects of this effort. With the plurality of tools and techniques being applied to analyze population-size datasets, there has been a growing apprehension within the field about the degree of analytic variability across neuroimaging results. In Chapter \ref{chap:software}, we helped address these concerns in regards to variation between fMRI analysis software. By reanalyzing three publicly available fMRI datasets in the three most popular analysis packages, we ultimately demonstrated the fragility of group-level fMRI results dependent on the software package chosen to analyze the data. Our main contribution here was the measurement of inter-software differences using a variety of quantitative methods. Dice coefficients, Bland-Altman plots and Euler Characteristic curves illuminated disparities between the final group-level statistic maps obtained with each analysis package in terms of the location, magnitude and topology of each software's activation profile. 

Our findings that weak effects may not generalize across software have highlighted the need for further examination of pipeline-related variation. While here we focussed on the statistic maps obtained at the end of an analysis, a limitation of this approach was that it meant our comparisons reflected the net accumulation of differences across the \textit{entire} pipeline, rather than diagnosing the precise procedures where the greatest variation between software transpired. In future work we plan to carry out additional analyses on the three datasets used in this effort, implementing a common preprocessing strategy before utilizing procedures from different packages in the remaining stages of the analysis. This will distinguish whether the largest sources of software-variability are during the preprocessing or statistical modelling of fMRI data, prompting a further assessment of individual procedures to find areas where the three packages can be harmonised. 

Alternatively, on the basis that each analysis package represents a peer-reviewed and valid analytic strategy, another line of work may include the development of techniques to synthesize inconsistent findings. While meta-analysis methods are routinely used in fMRI to aggregate data from separate studies, our setting is unique as all results are obtained by analyzing a \textit{single} source dataset within multiple software packages. Therefore, unlike a traditional meta-analysis, any inter-result variation is solely due to methodological differences between analysis software. As part of future work, we look to expand on current approaches to develop a series of `same-data meta-analysis' techniques. By accounting for the correlation between individual statistic maps obtained from numerous analyses of a single dataset, we hope to establish methods that can provide a calibrated, consensus result across software. These sort of techniques may benefit further efforts to combine data from replication studies, such as the \textit{Neuroimaging Analysis Replication and Prediction Study} \citep{Botvinik-Nezer2019-qu}, where a single fMRI dataset has been analyzed by multiple teams worldwide. 

In the second part of this thesis, we shifted our attention to the methods carried out for fMRI inference. Once again, big data played a key role in motivating this work; the introduction of population fMRI datasets have shed light on the practical limitations of current statical inference methods, providing ample power such that traditional testing methods essentially declare whole-brain activation. To overcome this, we endeavoured to develop a method that bypassed statistical testing to make inference on the practical \textit{effect sizes} of interest.

In Chapter \ref{chap:BOLD}, we extended on recent work by \citet*{Sommerfeld2018-zl} (\textit{SSS}) to compute Confidence Sets (CSs) on fMRI \%BOLD change maps, providing confidence statements about brain regions where \%BOLD effect sizes had exceeded, and fallen short of, a \textit{non-zero} cluster-forming threshold. In this work, we discovered that the methods used to evaluate empirical coverage for the simulations carried out in \textit{SSS} had biased the results upwards. By developing a more accurate assessment procedure based on linear interpolation, we demonstrated that the approach for computing CSs described in \textit{SSS} could suffer from under-coverage when applied to 3D synthetic data with moderate sample sizes. To remedy this, we adapted the method to incorporate a Wild $t$-Bootstrap and the use of Rademacher variables for multiplication of the bootstrapped residuals. Across a range of 2D and 3D simulations, we showed that empirical coverage performance for our modified procedure remained close to the nominal target level, suggesting that the method could be effectively applied to fMRI \%BOLD data.

In Chapter \ref{chap:cohen}, we made further advancements on the Confidence Sets for application to fMRI Cohen's $d$ effect size images. By deriving the statistical characteristics of the Cohen's $d$ estimator, we explored how the methods studied in Chapter \ref{chap:BOLD} could be adapted to compute Cohen's $d$ CSs. One of our main contributions here was the development of a transformation to normalize the distribution of the sample Cohen's $d$, motivating a procedure for obtaining Cohen's $d$ CSs in the transformed domain. Altogether, we formulated three separate algorithms to compute Cohen's $d$ CSs. By testing our methods on 2D and 3D Monte Carlo simulations, we found that two of these procedures performed particularly well. In the final part of this work, we demonstrated the Cohen's $d$ CSs on Human Connectome Project working memory task-fMRI data, and by comparing the CSs with statistical results obtained using a traditional inference procedure, we showed how the CSs can provide an improved localization of meaningful effects.

While in this work we have focussed on CSs, recently an increased amount of attention has been given to developing methods that estimate simultaneous confidence \textit{bands} for functional data \citep{Degras2017-sw,Telschow2019-lg}. A future study may investigate how confidence bands could be applied to fMRI effect size maps, similar in vein to the work carried out here on Confidence Sets. Whereas the CSs localize brain regions to assert where effect sizes exceed (and fall short of) a threshold, the purpose of the confidence bands would be to envelope the activation across the \textit{entire} brain. This would provide information about the maximum and minimum effect sizes in an image, that could then be used, for example, to determine an appropriate threshold for computing CSs. Finally, while Cohen's $d$ is commonly applied in fMRI to estimate effect sizes following a $t$-test, partial $R^{2}$ is also used to assess group-level results when multiple predictors are tested (e.g.\ with an $F$-test). As an extension on the methods developed here, a generalization of the Confidence Sets for application to fMRI partial $R^{2}$ maps may therefore be desirable.
